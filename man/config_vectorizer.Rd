% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/vectorizer.R
\name{config_vectorizer}
\alias{config_vectorizer}
\title{Configure vectorizer}
\usage{
config_vectorizer(x, tokenizer = NULL, max_words = 20000,
  doc_prop_max = 1, doc_prop_min = 0.001)
}
\arguments{
\item{x}{Data (character vector where each observation is a document of text)
that will be tokenized and used to build a dictionary. For machine learning
models, this should include only the training data.}

\item{tokenizer}{Function used to tokenize text.}

\item{max_words}{Maximum number of words/tokens to use.}

\item{doc_prop_max}{Maximum proportion of documents in which term appears}

\item{doc_prop_min}{Minimum proportion of documents in which term appears}
}
\value{
A vectorizer
}
\description{
Create a vectorizer object
}
